\chapter{Host Compiled Simulation}

Host Compiled Simulation is the current focus areas of research in the space of simulation. It is popular because it is simple to understand and develop compared to other approaches, and can provide highly accurate estimates of performance.

\gls{hcs} is based on the approach of Source Code Instrumentation. Instrumentation is the technique to modify the source code of an application, so as to extract useful information during the run-time of the application. In Host Compiled Simulation, the source code is instrumented to gain information of the time spent in executing the code on a particular target processor.

The source code of the application is analysed along with the cross-compiled binary code generated by the compiler for the target processor. Time spent in executing each basic block of the binary code is estimated and annotated to the corresponding basic block in the source code. For each memory access in the binary code, time spent in performing the operation on the target processor is estimated and annotated. This annotated time for each basic block and memory access is accumulated in a global variable, and reported at the end of the execution. 

The instrumented code is compiled for and run on the Host Machine, hence the name Host Compiled Simulation.

\section{Simple Example}
This simple example will be able to illustrate the concept of Host Compiled Simulation.

Consider the source code in Listing \ref{lst:sumCCode}. The function \textit{sum} calculates the sum of elements in an array and returns the result. The object dump from the binary code generated by the ARM cross-compiler is shown in Listing \ref{lst:sumObjCode}.

To accumulate the number of cycles spent in execution two global variables will be declared, \textit{execCycles} and \textit{memAccessCycles}.

From the binary code, 3 basic blocks can be identified. The first basic block starts from line number 2 to 3, the second is a loop from line 4 to 8 and the third between lines 9 and 10. These blocks can easily be matched to corresponding blocks in the source code.

\begin{table}
\begin{longtable}[c]{cccc}
\toprule 
	BlockID & Lines & BlockID & Lines \\
    \midrule
	1 & 1-3 & 1 & 2-4 \\
    \bottomrule
\end{longtable}
\end{table}

\begin{table}
\begin{longtable}[c]{cccc}
\toprule 
	\multicolumn{2}{c}{Basic Block in Binary} & \multicolumn{2}{c}{Matching block in Source}\\ 
	\multicolumn{1}{c}{BlockID} &
	\multicolumn{1}{c}{Lines} &
	\multicolumn{1}{c}{BlockID} &
	\multicolumn{1}{c}{Lines} \\
    \midrule
	1 & 1-3 & 1 & 2-4 \\
    \bottomrule
\end{longtable}
\end{table}

For each basic block, we will annotate the time spent in executing the instructions. For simplicity, let us assume that the processor has a single stage pipeline, and each instruction takes 1 cycle to execute. The estimate number of cycles is added to the global variable \textit{execCycles}.

Further, we can see one memory access on line 4, which corresponds to the loading of elements of the array. To estimate the time spent in loading this data, the cache hierarchy of the target system will be simulated. The cache simulation offers an API \textit{simDCache} to simulate data cache access and takes as parameter the address of the data and a flag to signify whether it is a read or write operation. The cache simulator returns the number of cycles spent in performing the memory access. This value is accumulated in the global variable \textit{memAccessCycles}. 

Also, the instruction cache access must be simulated. This is done at the basic block granularity. The cache simulator offers API \textit{simICache} which takes as parameters \textit{address} of the first instructions in the basic block, and \textit{size} of the basic block in bytes. The cache simulator returns the number of cycles spent in fetching the instructions. The value is also accumulated in global variable \textit{memAccessCycles}.

The instrumented code is shown in Listing [TODO].

\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[caption={Simple C Code},label={lst:sumCCode}]
int sum(int array[20])
{
	int i;
	int sum = 0;
	
	for (i=0; i<20; i++)
		sum += array[i];
	
	return sum;
}
\end{lstlisting}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[caption={Objdump Code},label={lst:sumObjCode}]
00008068 <sum>:
8068:     mov     r3, #0
806c:     mov     r2, r3
8070:     ldr     r1, [r0, r3]
8074:     add     r2, r2, r1
8078:     add     r3, r3, #4
807c:     cmp     r3, #80 ; 0x50
8080:     bne     8070 <sum+0x8>
8084:     mov     r0, r2
8088:     bx      lr
\end{lstlisting}
\end{minipage}

\begin{lstlisting}[caption={Instrumented Code},label={lst:sumInstCode}]
unsigned int execCycles;
unsigned int memAccessCycles;

int sum(int array[20])
{
	int i;
	int sum = 0;
	execCycles += 2;
	memAccessCycles += simICache(0x8068, 8);
	
	for (i=0; i<20; i++)
	{
		sum += array[i];
		memAccessCycles += simDCache(&array, READ);
		execCycles += 5;
		memAccessCycles += simICache(0x8070, 40);
	}
	
	execCycles += 2;
	memAccessCycles += simICache(0x8084, 8);
	return sum;
}
\end{lstlisting}

\section{Block Diagram}


\section{The Approach}
In this research a tool has been developed to automatically instrument the source code of a benchmark application. For accurate instrumentation, the tool analyses the source code along with the cross-compiled binary code generated by the compiler for the target processor.

When a program is executed on a processor, most of the time is spent in executing instructions on the processor pipeline, and fetching data from the memory.

The timing information for time spent in executing instructions in pipeline is annotated at the Basic Block granularity. A Basic Block is a set of instruction which are always executed in a sequence. Each basic block in the binary code is considered. It is assumed that all the data used by the instructions in the basic block is available in L1 Cache, and time spent in fetching data from memory is ignored for now. Each instruction in the basic block simulated to execute on the processor pipeline, and the number of cycles spent is calculated. Cycles spent in pipeline stalls due to interlocking (Control or Data Dependency) among instructions are accounted for. This information is then back-annotated to the corresponding basic block in the source code. Whenever the basic block is executed, the number of cycles spent are accumulated in a global variable. 

Note that at the start of each basic block, it is assumed that the processor pipeline is empty, which is not really the case when Branch Prediction Unit correctly predicts the jump from previous Basic Block to current Basic Block. To accommodate for this, Branch Prediction Unit has been simulated. At the start of each branch, an annotation is added which provides the start address of the branch to the Branch Prediction Emulation Unit which emulates the logic implemented in the target processor to predict branches. If the branch was predicted correctly, a certain number of cycles are subtracted from the total time to remove the penalty which was already added. 

To annotate the timing information for memory access, Cache Hierarchy must be simulated. To do this, each load/store instruction in the binary is identified and mapped to an instruction in the source code. To accurately simulate memory access, we need to reconstruct the memory address for the corresponding variable being fetched on the target system. We then simulate the access to this address in the cache. The cache simulator checks whether the data is present in one of the caches, or should be fetched from the memory. Accordingly, it returns with the number of cycles spent in fetching this data. The result is then accumulated in a global variable.

The annotated code is compiled, and run on the host machine. Accurate timing information is made available from the instrumentation. To calculate the power consumed, Power State Model approach is used. The processor is in a switching (running) state when instructions are being executed in the pipeline, and is in idle state while waiting for data to be fetched from the memory. The power consumed by the processor in each stage in unit time is known. By using this information, total power consumed in running the benchmark application on the target processor can be estimated. Similar approach is used for estimating the power consumed in fetching data from the memory.

\section{Mapping between Source and Binary Code}
For correctly instrumenting the source code, we need to know the accurate mapping between source code and binary code. This mapping is usually destroyed by the optimization phases of the compilers. The Compiler performs optimizations like partial or full loop unrolling, etc. %TODO Other Optimizations
This makes reconstruction of the mapping a challenging problem.

GDB uses debug information to map each instruction in the binary code to a line in the source code. However this mapping is highly inaccurate, and can not be used. Prominent techniques presented by research papers in the area use Control and Data Flow Analysis to reconstruct the mapping at a Basic Block granularity. 

In this project, the mapping algorithm described in [TODO] has been used. The high level source code is first cross-compiled using the compiler for the target processor. The intermediate code that is generated from the compiler front-end is in GIMPLE format. GIMPLE is a simple 3 address representation of the code, which has been optimized with the target independent optimization strategies. Since most of the optimization phases have already been applied to the code, it is expected that the Control Flow of the Intermediate Code is close to that of the binary code. The intermediate GIMPLE code is then converted back into C Code. To convert GIMPLE to C Code, the code from the tool desrcibed in [TODO] has been reused. The generated C Code is referred to as \gls{isc}.

Here after, the \gls{cfg} is generated from \gls{isc} and the cross-compiled binary. These \gls{cfg}s are matched. From observation, it has been noticed that the \gls{cfg}s still differ quite substantially. Special algorithm is required to match these \gls{cfg}s. 

The technique used in the project to match the \gls{cfg}s is a Graph Matching Algorithm using Depth First Traversal of the graphs along with special handling for particular optimizations. 

One such optimization that needs to be handled is merging of branches using Conditional Execution or Predicated Executed. For if-else branches with small code, the compiler optimizes the code by using Conditional Execution Instruction. The compare instruction is followed instructions inside the \textit{then} and \textit{else} branch which are predicated to indicate that the instructions will only be executed depending on the result of the compare instruction. The statements are viewed as one Basic Block in the Binary code, as the branch instructions are eliminated. Each instruction is fed to the processor pipeline and executed, but the results are only written back if the condition evaluates to \textit{true}. This saves the time spent in branching, and reduces the number of pipeline flushes.

To handle this case, the matching algorithm must identifies Basic Blocks in the binary that contain Conditional Execution Instructions, and appropriately maps a branch in the \gls{cfg} of the source code. A short example below will explain how this works.

%TODO Example for Conditional Execution

Similarly, other optimization techniques need to be handled specifically. Compilers provide an option to the developer to configure the Optimization Level to be used. With each level a set of optimization strategies are applied. Currently, in this project we focus only on O1 level optimization. The code can be later extended to accommodate for other optimizations.

In some cases, using a Graph Matching algorithm is not enough for accurate mapping. For instance, when two branches from a node look exactly the same, like an if-then-else branch shown in the following example, the matching algorithm is unable to identify the \textit{then} branch from the \textit{else} branch. To map this, we use information from GDB.

There might be some corner cases that might occur using this approach. Most corner cases are identified by the tool and an error message is reported to tell the user, that accurate mapping could not be found. Also a graphical representation of the \gls{cfg}s is presented depicting the mapping generated by the tool, to help the user identify any mistakes that might have occurred. As of now there is no mechanism to utilize user assistance in fixing mapping issues. This feature can be added as an extension.

The Graph Matching Algorithm returns a data structure with \gls{cfg}s generated for each function from the source code and the binary code, along with the mapping information. Each basic block in source code maps to one block in the binary, but the basic block in binary may be matched to multiple blocks in the source code. This information is passed on to the next steps.

\section{Instruction Execution Time Annotation}
Time information for execution of instructions in the processor pipeline is annoated at Basic Block granularity. 






